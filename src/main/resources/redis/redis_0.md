## Redis

+ **Redis分布式锁**   
    分布式锁是控制分布式系统之间同步访问共享资源。
    Redis实现锁的命令：   
    1、SETNX,用法SETNX key value。SETNX是[set if not exits]，如果不存在就执行set操作，设置成功返回1，否则返回0；
    SETNX没有设置过期时间，会导致线程一直持有锁。
    2、EXPIRE,用法 EXPIRE Key Seconds 给某一个key设置过期时间。
    加锁可以分为两个操作：   
    ```
    `SETNX Key 1`
    `EXPIRE Key Seconds`
    ```
    可以设置过期时间，但是整个操作不是原子性的，如果执行完SETNX之后出现异常，设置的锁没有过期时间，会导致线程线程一直持有锁。   
    **解决**：
    可以用相关lua脚本解决原子性问题：
    ```
    if (redis.call('setnx', KEYS[1], ARGV[1]) < 1)
    then return 0;
    end;
    redis.call('expire', KEYS[1], tonumber(ARGV[2]));
    return 1;
    
    // 使用实例
    EVAL "if (redis.call('setnx',KEYS[1],ARGV[1]) < 1) then return 0; end; redis.call('expire',KEYS[1],tonumber(ARGV[2])); return 1;" 1 key value 100  
    ```
    可以使用`set key value [EX seconds][PX milliseconds][NX|XX]`命令解决。   
    EX seconds:设置过期时间，单位为秒。   
    PX milliseconds：设置过期时间，单位为毫秒。   
    NX：当key不存在是设置值。   
    XX：当可以存在时设置值。   
    加锁：
    给每个锁一个唯一ID，加锁是生成，解锁是判断。给锁设置对应的过期时间。
    ```java
    public static boolean tryLock(String key, String uniqueId, int seconds) { 
      return "OK".equals(jedis.set(key, uniqueId, "NX", "EX", seconds));
    }
    ```
    解锁：   
    解锁时使用lua脚本，先判断唯一ID是否相同，在进行相关解锁操作。
    ```java
    public static boolean releaseLock(String key, String uniqueId) { 
      String luaScript = "if redis.call('get', KEYS[1]) == ARGV[1] then " + "return redis.call('del', KEYS[1]) else return 0 end";
       return jedis.eval( luaScript, Collections.singletonList(key), Collections.singletonList(uniqueId) ).equals(1L);
    }
    ```
    [Redis分布式锁问题：](https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/)   
    1、锁的时间大小设置问题；若时间设置过短，线程A还在执行但是锁已经释放，此时线程B也能获取到该锁，会导致数据问题。   
        将A的线程过期时间设置足够长。    
        为获取锁的线程增加守护线程，为将要过期但未释放的锁。   
    2、锁误解除；如果不加唯一ID，同样是线程A还在执行但是锁已经释放，此时线程B也能获取到该锁，此时A进行删除锁操作，但是B还没有执行完成，此时删除的是B的锁。   
        增加唯一ID可以解决。      
    3、不可重入,当前线程持有锁的情况下，再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。   
        Redis可以通过对锁进行重入计数，加锁+1，释放锁-1，直到为0锁释放完成。   
    4、客户端无法等待锁释放：上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。   
        可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。   
        另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。   
    5、redis集群锁：  
        **_主备切换问题_**。Redis主从方式部署，主从同步数据有同步和异步两种方式，redis将指令记录在本地Buffer中，然后异步将Buffer中的指令同步到从节点，从节点一边
        执行同步指令来达到和主节点状态一致，一边向主节点反馈同步情况。  
        当主节点挂掉之后，从节点会取而代之，但是客户端无明显感知。当A节点获取到锁，指令还未同步，此时A节点挂掉，从节点提升为主节点，新的主节点没有锁的数据，此时B仍能获取到锁。   
        ![avatar](https://github.com/NPFDamon/Study/blob/main/src/main/resources/redis/redis-lock-07.png)   
        **_集群脑裂_**。脑裂问题指因为网络原因，导致redis的master节点跟slave和sentinel集群处于不同的网络分区。因为sentinel无法感知到master的存在，
        所以讲slave节点提升为master节点，此时存在两个不同的master节点。Redis Cluster 集群部署方式同理。当不同的客户端连接到不同的master时两个客户端可以持有一把锁。   
        ![avatar](https://github.com/NPFDamon/Study/blob/main/src/main/resources/redis/redis-lock-08.png)   
        _Redis 以其高性能著称，但使用其实现分布式锁来解决并发仍存在一些困难。Redis 分布式锁只能作为一种缓解并发的手段，如果要完全解决并发问题，仍需要数据库的防并发手段。_   
    **Redisson分布式锁：**   
        Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，
        还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。   
        Redisson提供了使用Redis的最简单和最便捷的方法。     
        RedissonLock同样没有解决节点挂掉的时候，存在锁丢失的风险。而现实情况是有一些场景无法容忍的，所以 Redisson 提供了实现了redlock算法的 RedissonRedLock，
        RedissonRedLock 解决了单点失败的问题，代价是需要额外的为 RedissonRedLock 搭建Redis环境。所以，如果业务场景可以容忍这种小概率的错误，则推荐使用 RedissonLock， 
        如果无法容忍，则推荐使用 RedissonRedLock。  
    **redlock算法：**   
        1,获取当前Unix时间，以毫秒为单位。   
        2,依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个尝试从某个Reids实例获取锁的最大等待时间
        （超过这个时间，则立马询问下一个实例），这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。   
        这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。   
        3,客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁消耗的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，
        并且使用的总耗时小于锁失效时间时，锁才算获取成功。   
        4,如果取到了锁，key的真正有效时间 = 有效时间（获取锁时设置的key的自动超时时间） – 获取锁的总耗时（询问各个Redis实例的总耗时之和）（步骤3计算的结果）。   
        5,如果因为某些原因，最终获取锁失败（即没有在至少 “N/2+1 ”个Redis实例取到锁或者“获取锁的总耗时”超过了“有效时间”），客户端应该在所有的Redis实例上进行解锁
        （即便某些Redis实例根本就没有加锁成功，这样可以防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。  
    **watchDog机制**[avatar](https://www.cnblogs.com/keeya/p/14332131.html)：  
        
  - 如果拿到分布式锁的节点宕机，且这个锁正好处于锁定状态，会出现锁死的状态，未来避免这个情况发生，锁都会设置一个过期时间。这样就存在了一个问题，假如一个线程拿到了锁，
    并设置了30s的过期时间，在30s后事务还未执行完成，如果锁释放了就会存在问题，**redission才用watch dog自动续期机制解决这个问题**。  
  - Redission提供了一个监控的看门狗，他的作用是在redission实例被关闭前不断地延长锁的有效期，也就是说如果一个线程拿到锁但是逻辑一直没有完成，那么看门狗会帮助线程不断地延迟
  - 锁超时时间，锁不会因为超时而被释放。  
  - 默认情况下，看门狗的续期时间是30s，可以通过Config.lockWatchdogTimeout来另行指定。  
  - 另外Redission还提供了可以制定leaseTime参数的加锁方法来制定加锁的时间。超过这个时间后便自动解开了，不会延长锁的有效期。 
  
    **关键点**  
        1. watch dog在当前节点存活时没10s给分布式锁的key续期30s；  
        2. watch dog机制启动，且代码没有释放锁的操作时，watch dog会不断的给锁续期；  
        3. 从2可看出，如果释放锁的操作因为异常没有被执行，那么锁就无法被释放，**所以释放锁的操作一定要在finally{}里执行；**  
        4. 如果释放锁本身异常了，watch dog不会再续期了。因为在释放锁的操作中会先从EXPIRATION_RENEWAL_MAP中获取ExpirationEntry对象，然后remove。该对象在执行对应的lua脚本
        前已经被移出了。  
+ **Redis缓存**    
    缓存的收益：   
    1，高性能：数据库查询速度慢(磁盘IO，逻辑运算)，缓存中查询速度非常快（内存查询，KV结构，简单逻辑运算）。   
    2，高并发：缓存是走内存的，内存天然就支撑高并发。   
    缓存的问题：   
    1，缓存数据和数据库一致性问题。   
    2，缓存雪崩。   
    3，缓存穿透。   
    4，缓存击穿。   
    5，缓存并发竞争。      
    [缓存数据和数据库一致性问题：](https://developer.aliyun.com/article/712285)      
    * 先淘汰缓存，再更新数据库:   
    1、在正常情况下，A、B两个线程先后对同一个数据进行读写操作：   
      A线程进行写操作，先淘汰缓存，再更新数据库    
      B线程进行读操作，发现缓存中没有想要的数据，从数据库中读取更新后的新数据      
    此时没有问题   
    2、在并发量较大的情况下，采用同步更新缓存的策略：   
      A线程进行写操作，先成功淘汰缓存，但由于网络或其它原因，还未更新数据库或正在更新   
      B线程进行读操作，发现缓存中没有想要的数据，从数据库中读取数据，但此时A线程还未完成更新操作，所以读取到的是旧数据，并且B线程将旧数据放入缓存。注意此时是没有问题的，因为数据库中的数据还未完成更新，所以数据库与缓存此时存储的都是旧值，数据没有不一致
      在B线程将旧数据读入缓存后，A线程终于将数据更新完成，此时是有问题的，数据库中是更新后的新数据，缓存中是更新前的旧数据，数据不一致。如果在缓存中没有对该值设置过期时间，旧数据将一直保存在缓存中，数据将一直不一致，直到之后再次对该值进行修改时才会在缓存中淘汰该值
    此时可能会导致cache与数据库的数据一直或很长时间不一致    
    3、在并发量较大的情况下，采用异步更新缓存的策略：   
      A线程进行写操作，先成功淘汰缓存，但由于网络或其它原因，还未更新数据库或正在更新   
      B线程进行读操作，发现缓存中没有想要的数据，从数据库中读取数据，但B线程只是从数据库中读取想要的数据，并不将这个数据放入缓存中，所以并不会导致缓存与数据库的不一致
      A线程更新数据库后，通过订阅binlog来异步更新缓存   
    此时数据库与缓存的内容将一直都是一致的   
    _进一步分析_：   
    如果采取同步更新缓存的策略，即如果缓存中没有数据，就读取数据库并将数据直接放入缓存，可能会导致数据长时间的不一致
    在这种情况下，可以用一些方法来进行优化：   
    1、用串行化的思路   
      即保证对同一个数据的读写严格按照先后顺序串行化进行，避免并发较大的情况下，多个线程同时对同一数据进行操作时带来的数据不一致性。
    2、延时双删+设置缓存的超时时间   
      不一致的原因是，在淘汰缓存之后，旧数据再次被读入缓存，且之后没有淘汰策略，所以解决思路就是，在旧数据再次读入缓存后，再次淘汰缓存，即淘汰缓存两次(延迟双删)
    引入延时双删后，执行步骤变为下面这种情形：   
      A线程进行写操作，先成功淘汰缓存，但由于网络或其它原因，还未更新数据库或正在更新   
      B线程进行读操作，从数据库中读入旧数据，共耗时N秒   
      在B线程将旧数据读入缓存后，A线程将数据更新完成，此时数据不一致   
      A线程将数据库更新完成后，休眠M秒(M比N稍大即可)，然后再次淘汰缓存，此时缓存中即使有旧数据也会被淘汰，此时可以保证数据的一致性   
      其它线程进行读操作时，缓存中无数据，从数据库中读取的是更新后的新数据   
    利用延迟双删，可以很好的解决数据不一致的问题，其中A线程休眠的M秒，需要根据业务上读取的时间来衡量，只要比正常读取消耗的实际稍大就可以。
    但是个人感觉实际业务中需要根据场景来设置休眠的时间，这个不好确定。   
    引入延迟双删之后，存在两个问题：   
    1,A线程需要在更新完数据库之后，还需要等待M秒再次淘汰缓存，所有操作都完成，这一操作才是真正完成，降低了更新操作的吞吐量；
        解决办法：采用"异步淘汰"策略，将更新操作放到第二个线程中，A线程更新完成后直接返回。   
    2,如果第二次淘汰失败，依旧会出现数据不一致问题。   
        解决办法：采用重试机制，当第二次失败后，报错并继续重试，一直到成功。   
    _总结_：在单节点环境下，用"先删除，后更新"的策略，如果采用同步更新策略，可能会导致数据长时间不一致，可以通过一些方法来尽量避免不一致。如果采用异步更新策略，数据不一致的概率很小很多。     
    * 先更新数据库，再淘汰缓存   
    在正常情况下：   
      A线程进行写操作，更新数据库，淘汰缓存   
      B线程进行读操作，从数据库中读取新的数据   
    不会有问题   
    
    在并发较大的情况下，情形1：   
      A线程进行写操作，更新数据库，还未淘汰缓存   
      B线程从缓存中可以读取到旧数据，此时数据不一致   
      A线程完成淘汰缓存操作   
      其它线程进行读操作，从数据库中读入最新数据，此时数据一致   
    不过这种情况并没有什么大问题，因为数据不一致的时间很短，数据最终是一致的   
    
    在并发较大的情况下，情形2：   
      A线程进行写操作，更新数据库，但更新较慢，缓存也未淘汰   
      B线程进行读操作，读取了缓存中的旧数据   
    但这种情况没什么问题，毕竟更新操作都还未完成，数据库与缓存中都是旧数据，没有数据不一致   
    
    在并发较大的情况下，情形3：   
      A线程进行读操作，缓存中没有相应的数据，将从数据库中读数据到缓存，   
    此时分为两种情况，还未读取数据库的数据，已读取数据库的数据，不过由于网络等问题数据还未传输到缓存   
      B线程执行写操作，更新数据库，淘汰缓存   
      B线程写操作完成后，A线程才将数据库的数据读入缓存，对于第一种情况，A线程读取的是B线程修改后的新数据，没有问题，对于第二种情况，A线程读取的是旧数据，此时数据会不一致
    不过这种情况发生的概率极低，因为一般读操作要比写操作要更快   
    万一担心存在这种可能，可以用“延迟双删”策略，在A线程读操作完成后再淘汰一次缓存   
    _总结_：无论是采用同步更新缓存(从数据库读取的数据直接放入缓存中)，还是异步更新缓存(数据库中的数据更新完成后，再将数据同步到缓存中)，都不会导致数据的不一致
         该方案主要只需要担心一个问题：如果第二步淘汰缓存失败，则数据会不一致
         解决办法之前也提到过，用“重试机制”就可以，如果淘汰缓存失败就报错，然后重试直到成功
    * 单节点下两种方案对比   
    先淘汰缓存再更新数据库：     
        采用同步更新时，可能会导致长时间数据不一致问题，如果采用延迟双删优化，还需要考虑延时多长时间的问题——读的效率较高，但是数据一直性问题，需要靠其他手段来保证。   
        采用异步更新缓存策略，不会导致数据不一致问题，但在数据库完成更新之前都需要到数据库进行读取，读的效率不高，保证的数据的一致性，适用于对一致性要求高的业务。   
    先更新数据库再淘汰缓存：   
        无论同步还是异步都不会造成**最终**数据不一致问题，再更新数据库期间，缓存中的数据会被读取，可能会有一段时间的数据不一致，但是读的效率高，保证的读的效率，
        如果对于业务数据一致性要求不高的情况下,这种方案最合适。
    _其它_：
        重试机制可以采取MQ来实现。    
        通过binlog来异步更新缓存，可以通过canal中间件来实现。  
* **缓存常见问题**   
    * 缓存雪崩   
    缓存在同一时间大量失效，导致大量请求直接落在数据库上，造成数据库短时间内收到大量请求。   
    有一些大量访问的数据(热点数据)在某一时间大面积失效，导致对应的请求落到数据库上。   
    解决方案：   
        1，在设置redis失效时间时，加上一个随机值，保证不会再同一时间内大量缓存数据失效。   
        2，在集群环境下，将热点数据均匀分散到不同的集群中。或者设置热点数据永不不过期，更新数据时直接更新缓存。    
        3，代码架构层使用hystrix 限流&降级，避免MySQL被打死。     
        4，Redis持久化，一旦redis 挂掉之后，快速重启恢复数据。   
    * 缓存穿透   
    缓存和数据库里都没有对应的数据，用户不断发送没有数据的请求(数据库id都是大于0的，我一直用小于0的参数去请求你，每次都能绕开Redis直接打到数据库，数据库也查不到，每次都这样，并发高点就容易崩掉了。)。   
    数据从缓存和数据库都取不到值的时候，可以给该值设置一个空值。给参数做合法性校验。    
    使用布隆过滤器。   
    * 缓存击穿      
    指热点key，不停的受到大量并发的集中访问，当这个key失效时，大量的请求直接请求到数据库，造成数据库压力增大甚至宕机。    
    设置热点数据永不过期。或者使用互斥锁，在第一个请求数据库的时候使用互斥锁进行锁住，其他线程再来查询时，得不到锁就处于等待状态，等第一个线程查到了数据，
    然后放入到缓存中，后面的线程再来查询，发现缓存中已经有数据，可以直接走缓存查询。