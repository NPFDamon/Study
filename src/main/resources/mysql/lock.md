## Mysql Lock 
 
+ **MySQL锁**   
    表锁：每次都是锁整张表；   
    行锁：每次锁一行数据；  
    全局锁：对整个数据库实例加锁，MySQL提供了全局读锁的命令：flush tables with read lock 如果需要整库处于只读状态，可以使用此条命令；
    以下语句会被阻塞：数据更新语句（增删改）、数据定义语句（建表、修改表结构等）和更新类事务的提交语句。全局锁使用场景，全库逻辑备份，使库处于只读状态，
    但是这样子备份会导致很大问题（暂停写入，主从同步延迟）。   
    MyISAM引擎只支持表锁，每次都是锁整张表；InnoDB不仅支持表锁，还支持更加细粒度的行锁，所以InnoDB的性能更高。   
    无论行锁还是表锁，MySQL的锁分为两类：   
    + S锁(shared(S) locks)，称为共享锁，运行事务读取一条数据。事务读取记录的时候获取S锁，运行多个事务获取S锁，相互之间不会影响。   
    + X锁(exclusive(X) locks)，称为独占锁，运行事务更新或删除一条数据。事务写入记录的时候获取X锁，且只允许一个事务获取X锁，其他事务需要阻塞等待。   
    X锁与任何锁都不兼容，而S锁仅和S锁兼容。S锁和X锁都是行锁。   
    
    |   冲突    |   S    |  X     |    
    |   ---    |  ---   |  ---   |     
    |    S     | 不冲突  |  冲突  |    
    |    X     |  冲突   |  冲突  |    
    
    普通的Select查询时不加锁的，而`select ... lock in share mode`这种读取需要加上S锁，`select ... for update`需要加上X锁。   
    InnoDB表锁：  
    `Lock tables xxx read`对xxx表加上S锁。   
    `Lock tables xxx write`对xxx表加上X锁。   
    InnoDB表锁很鸡肋，update 、select 要用的就是行锁，不可能用粒度更粗的表锁。唯一用到表锁的是DDL语句,比如alter table xxx 的时候，这个时候应该
    锁整张表，防止查询和修改，但是MySQL已经提供了MDL(Metadata locks)用来阻塞。表锁就排不上用场了。（当恢复数据的时候，手动锁表还原数据的时候，应该应道表锁）   
    除此之外，InnoDB存储引擎支持多粒度锁定，这种锁定运行事务在*表级上的锁*和*行级上的锁*同时存在。为了支持在不同粒度上进行加锁操作，InnoDB支持一种
    额外的锁定方式，成为意向锁。**意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度上进行加锁。**   
    意向锁：   
    + 意向共享锁(IS lock)：事务想要获取一张表中某几行的共享锁。   
    + 意向排它锁(IX lock)：事务想要获取一张表中的几行排它锁。   
    意向锁是*表级别的锁*,当需要对表中的某条记录加S锁的时候,现在这个表上加IS锁,表明此时表内有S锁。当需要对表内的对象加X锁时，先在表上加IX锁,表明此时
    表内有X锁。这样操作之后，如果需要加表锁，就不需要遍历所有的记录去找行锁了，自己看表上是否有IS 和 IX锁就行了。   
    
    |兼容性 |IS   |   IX   |   S    |    X   |
    | ---  |---  | ---    | ---    |  ---   |
    |IS    |兼容  | 兼容   | 兼容    | 不兼容  |   
    |IX    |兼容  | 兼容   | 不兼容  | 不兼容  |   
    |S     |兼容  | 不兼容 | 兼容    | 不兼容  |   
    |X     |不兼容 | 不兼容 | 不兼容  | 不兼容  |   
    
    * 锁的三种算法：   
    + Record Lock：单个行记录上的锁      
    + Gap Lock: 间隙锁，锁定一个范围，但不包含记录本身   
    + Next-key Lock:Gap Lock + Record Lock,锁定一个范围和记录本身   
    Record Lock总是会去锁定索引记录，如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，那么此时InnoDB存储引擎会使用隐式主键来进行锁定。   
    间隙锁是给还未存在的记录加上锁，房子幻读的出现。例如一个索引有10，11，13和20四个值,那么间隙锁的区间为：
    (-∞,10),   
    (10,11),   
    (11,13),   
    (13,20),   
    (20,+∞)
    此时如插入范围为12的值就会被间隙锁锁住，这样避免了幻读(当某个事物读取某个范围记录的时候,另外一个事务又在该范围记录内插入了新的记录，当事务再次读取这个
    范围记录的时候，会产生幻读 或 在同一事务下，连续执行两次相同的SQL语句可能导致不同的结果，第二次的SQL可能返回之前不存在的值)的产生。
    Gap Lock是个开区间而Next-key Lock是个前开后闭的区间，上面的例子在Next-key Lock下是：   
    (-∞,10],   
    (10,11],   
    (11,13],   
    (13,20],   
    (20,+∞]
    这样会锁住10，11，13，20 20+...记录，这样就能防止查询此数据出现幻读。   
    当查询的索引含有唯一属性时，InnoDB会对Record Lock进行优化，将其降级为Record Lock即锁住索引本身，而不是范围。
    **注意：Next-key Lock降级为Record Lock仅在查询的列是唯一索引的时候。**    
    在默认的事务隔离级别(即Repeatable read)下,InnoDB采用Next-key Lock机制来避免幻读现象。而在隔离级别为Read-Committed下仅采用Record Lock。   
    插入意向锁(Insert Intention Locks),也是一种间隙锁，但不是锁定间隙，而是等待某个间隙，例如上面例子如果插入事务C插入ID=12，由于间隙锁给阻塞了，
    所以事务C会生成一个插入意向锁,表明等待这个间隙锁释放。并且插入意向锁之间不会阻塞，因为它们的目的也是只等待这个间隙被释放，所以插入意向锁之间没有冲突   
    + AUTO-INC Locking是一种特殊的表锁机制，用于自增列插入数据使用，在InnoDB中，对每个含有自增长值的表都有一个自增长计数器(auto-increment counter)。
    当含有自增长器的表在进行插入时，这个计数器会被初始化，插入操作会依据这个自增长器的值加1赋予自增长列。为了提高插入的性能，锁不是在完成一个事务之后就被释放，
    而是在完成自增长值插入的SQL执行完成之后才释放。   
    
    **脏读**：事务对缓冲池中的记录进行修改，并且还没有提交，脏数据是未提交的数据，脏读是一个事务可以读取另一个事务未提交的数据。违反了数据量的隔离性。   
    **不可重复读**：一个事务内多次读取同一事务。在这个事务还没有结束时，另外一个事务也访问该同一组数据，并做了一些DML操作。因此在第一个事务两次读取数据之
    间，由于第二个事务的修改,第一个事务两次读取的数据可能是不一样的。这样就发生了在一个事务内两次相同的读取得到的数据不一样的情况，称为不可重复读。
    脏读读取的是未提交的数据，为不可重复读读取的是已提交的数据。         
    InnoDB引擎中，通过Next-key Lock算法避免不可重复读。在MySQL官方文档中，不可重复读的问题定义为Phantom Problem，即幻读现象。在Next-key Lock
    算法下,对索引的扫描，不仅是锁住扫描到的索引，而且还锁住这些索引覆盖的范围。因此在这个索引范围内插入是不允许的。这样就避免了另外的事务在这个范围内
    插入数据导致不可重复读现象。MySQL默认隔离级别为Read Repeatable，采用Next-key Lock算法，避免了不可重复读现象。   
    **丢失更新**：一个事务的更新会被另一个事务的更新操作覆盖。从而导致数据不一样。在数据库的任何隔离级别下都不会导致数据库理论上的丢失更新e问题。   
+ **锁优化**   
    InnoDB的行级锁最大的优势就是增强了高并发的处理能力，缺点就是复杂性较高、易死锁，且基于索引实现有一定弊端。我们要做的就是扬长避短，合理利用InnoDB行级锁定，为此我们就应该做的：   
    1、尽可能让所有的数据检索都通过索引实现，因为InnoDB行级锁是基于索引实现的，没有索引或无法使用索引系统会改为使用表级锁。   
    2、合理设计索引，以缩小加锁范围，避免“间隙锁”造成不该锁定的键值被锁定。  
    3、尽量控制事务的大小，因为行级锁的复杂性会加大资源量以及锁定时间。   
    4、使用较低级别的事务隔离，以减少因实现事务隔离而付出的成本。   
    5、避免死锁，可以通过如下方式实现：   
    （1）类似的业务模块中，尽可能按照相同的访问顺序来访问，防止产生死锁。   
    （2）同一个事务中，尽量做到一次性锁定需要的所有资源。   
    （3）对于易产生死锁的业务部分，增大处理颗粒度，升级为表级锁以降低死锁产生的概率。   
    

    