## 分布式相关
+ **CAP理论**   
    一个分布式系统最多只能同事满足一致性(Consistency)-C,可用性(Availability)-A和分区容错性(Partition tolerance)中三项中的两项。   
    ![avatar](https://github.com/NPFDamon/Study/blob/main/src/main/resources/distributed/cap.jpeg)     
    
    * Consistency 一致性   
        一致性指`all nodes see the same data at the same time`，即所有节点在同一时间的数据完全一致。   
        对于一致性又可分为强/弱/最终一致性三类。   
        + 强一致性：要求更新过的数据都能被后续的访问看到，这就是强一致性。   
        + 若一致性：能容忍后续的部分数据或者全部数据访问不到，就是若一致性。   
        + 最终一致性：如果经过一段时间后能看到更新后的数据，就是最终一致性。   
    * Availability 可用性      
        可用性指`Reads and writes always succeed`，即服务在正常相应时间能一直可用。   
    * Partition Tolerance 分区容错性   
        分区容错性指`the system continues to operate despite arbitrary message loss or failure of part of the system`，即分布式系统
        某个节点或网络分区遇到故障的时候，仍然可用提供一致性或可用性的服务。   
        
    在CAP中有三种选择：   
    1，CA:放弃分区容错性，来达到可用性和一致性。把所有和事务相关的内容都放到一台机器上，避免网络分区。这样根不存在网络分区的情况。(不再是分布式系统)
    2，AP:放弃一致性，来成就可用性和分区容错性。可以及时获取数据，但是数据可能是不一致的。即使是不一致的，也有马上获取这个数据。(Zookeeper,Nacos)   
    3，CP:放弃可用性，来成就一致性和分区容错性。当出现网络分区时，需要等数据一致后再去获取数据，此时短时间内无法获取数据，失去可用性。(Eureka,Nacos)   
    在分布式系统中P是客观存在的，不选P，一旦发生错误，整个系统都不可用了，这不符合实际需求。所以只能从C和A中选择一个。   
    对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，
    舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。   
   
    对于涉及到钱财这样不能有一丝让步的场景，C必须保证。网络发生故障宁可停止服务，这是保证CA，舍弃P。还有一种是保证CP，舍弃A。例如网络故障事只读不写。
    
+ **BASE和最终一致性**   
    BASE是`Basically Available Soft Sate和Eventual consistency`的简写，意思是“碱”。
    ACID是关系数据库中的事务的四个性质。在NoSQL数据库中BASE（碱）和ACID（酸）是对应的。   
    在关系型数据量追求的是ACID的一致性，而在NoSQL数据库中追求的是BASE特性。   
    BASE的核心思想是即使无法做到强一致性,但是每个应用可以根据自己的业务特点，采用适当的方式达到最终一致性。`也就是牺牲数据的一致性来满足系统的高可用性，
    系统中一部分数据不可用或不一致时，仍需要保持系统的"主要可用
    
    BASE特性： 
    * 基本可用(Basically Available)   
        值一个分布式系统的一部分变得不可用时，其他部分仍能正常使用，也就是允许分区失败的出现。例如：一个数据库系统部署了很多节点，有可能一两个节点出现了失败，但是整个系统依然是可用的。   
    * 软状态(Soft State)    
        与硬状态相对应，指状态可以有一段时间不同步，具有不同步的时间窗口，具有一定的滞后性。 
        硬状态，数据库数据必须一致保证数据库状态的一致性，指任意时刻的数据都是正确的。     
    * 最终一致性(Eventual Consistency)   
       最终一致性为弱一致性的一种特例，如果经过一段时间后能看到更新后的数据，就是最终一致性。根据数据更新后进程访问时间的**时间**和**方式**的不同可以区分为：   
       1，因果一致性：如果进程A通知进程B它已经更新了一个数据项，那么进程B的后续访问将获取进程A的最新值。比如，我通知你，你就能获取后面的更新值，其他进程C、D，
       我没有通知到你，你就访问不到我刚刚写的值，只能最终能访问到，不是马上就访问到。   
       2，读自己所写：当进程A执行一个更新操作后，它自己总是能够访问最新值，不会读到旧值。   
       3，单调读一致性：如果进程已经看到过数据对象的某个值，那么任何后续访问都不会返回之前的旧值。   
       4，会话一致性：把访问存储系统的过程，放到会话上下文进程中，这个时候只要这些会话存在，系统就可以保证"读自己之所写一致性"。   
       5，单调写一致性：系统需保证来着同一进程的写操作是按照顺序执行的。同一个进程可能发生多个写操作，写操作有先有后，系统必须保证这些写操作按照顺序执行。   

+ **分布式事务**          
    `分布式事务指事务的参与者，支持事物的服务器，资源服务器以及事务管理器分别位于不同的分布式系统的不同节点上。`   
    不同与ACID的刚性事务，在分布式场景下基于BASE理论，就出现了柔性事务的概念。想要通过柔性事务来达到最终一致性，就需要依赖一些特性，这些特性在具体的
    方案中不一定都满足，因为不同的方案要求不一样；但是都不满足的话是不可能的做柔性事务的。　　　
    分布式事务的解决方案：　　　
    *　两阶段提交（２ＰＣ）／ＸＡ　　　
    **两阶段提交是一种强一致性设计**。两阶段提交，就是要分两步提交。存在一个负责协调各个本地资源管理器的事务管理器。本地资源管理器一般是通过数据库实现，事务管理器在第一阶段的时候询问
    各个资源管理器是否都准备就绪，如果每个资源管理器的回答都是确认，则第二个阶段提交事务，如果任意一个资源管理回答是no则回滚事务。   
     ![avatar](https://github.com/NPFDamon/Study/blob/main/src/main/resources/distributed/2pc-1.png)     
     ![avatar](https://github.com/NPFDamon/Study/blob/main/src/main/resources/distributed/2pc-2.png)     
     大致流程：   
     第一阶段(prepare):事务管理器向所有本地资源管理器进行请求，**同步等待**询问其状态是否为ready，所有参与者都将本地事务是否成功的信息告诉协调者；   
     第二阶段(commit/rollback):事务管理器根据所有本地资源管理器的反馈，通知所有本地管理器，步调一致的在所有分支上进行提交或者回滚。   
     存在的问题：   
     - 同步阻塞：第一阶段协调者要等待所有参与者响应才会进行下一步操作，当然第一阶段的**协调者有超时机制**，假设因为网络原因没有收到某参与者的响应或某参与者挂了，
     那么超时后就会判断事务失败，向所有参与者发送回滚命令。   
     - 单点故障：协调者是一个单点，一旦事务管理者出现故障，整个系统将不可用。协调者出现问题，通过选举得到新的协调者，会出现数据不一致的情况。      
     - 数据不一致：在阶段二，如果事务管理器只发生了部分commit消息，此时网络发生异常，那么只有部分参与者接收到commit，也就是说只有部分参与者参加了事务，使系统变得不可用。   
     - 不确定性：当协调事务管理器发送commit之后，并且此时只有一个参与者收到了commit，那么该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确认该
     条消息是否已经提交成功。   
     * 三阶段提交(3PC)   
     3PC的出现是为了解决2PC的一些问题，相比于2PC他在参与者中加入了**超时机制**，并且新增了一个阶段使参与者可以利用这一阶段统一各自状态。   
     3PC包含了准备阶段，预提交阶段和提交阶段，对应的英文就是：CanCommit、PreCommit 和 DoCommit。   
     第一阶段，准备阶段，**只是询问**所有参与者是否可以执行事务操作，**并不在本阶段执行事务操作**。   
     第二阶段，预提交阶段，当第一阶段所有参与者都返回yes的时候，在第二阶段中才执行事务操作。   
     第三阶段，提交阶段，根据第二阶段的结果进行commit或者rollback操作。   
     ![avatar](https://github.com/NPFDamon/Study/blob/main/src/main/resources/distributed/3pc.png)     
     在3PC中，准备阶段不会执行事务，而是询问此时的参与者是否有条件接受这个事务，因此不会一来就锁住资源，使得在**某些资源不可用时所有参与者都进行阻塞**(2PC缺点)。   
     预提交阶段起到了统一状态的作用，在预提交阶段前(准备阶段)所有事务都还为回应，在预提交阶段表明所有参与者都已经回应了。   
     由于多引入一个阶段，因此在正常流程中性能会差一些，因为绝大部分情况下资源应该都是可用的，这样等于每次明知可用执行还得询问一次。   
     参与者引入超时机制，使参与者不用一直等待，如果使预提交阶段命令超时，**事务不会进行提交**，什么也没有做；如果在提交阶段超时，**参与者会提交事务**，
     因为在这一阶段大概率是提交的。   
     3PC 用参与者超时机制，解决了协调者故障后参与者的阻塞问题。   
     `
     在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。
     所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。
     `
     * TCC（Try-Confirm-Cancel）   
     Try：指**预留**，即资源的预留和锁定。   
     Confirm：指确认操作，这一步其实就是真正的执行了。   
     Cancel:指撤销操作，把预留阶段的动作撤销。(回滚补偿机制)   
     ![avatar](https://github.com/NPFDamon/Study/blob/main/src/main/resources/distributed/tcc.png)     
     TCC需要对每一个操作都定义三种不同的动作Try - Confirm - Cancel。TCC对业务的侵入较大和业务紧耦合。但是TCC数据一致性的实时性高，因此其在很多金融、电商场景中大量采用。    
     撤销和确认操作的执行可能需要重试，因此需要保证幂等操作。   
     1，通过唯一键进行处理，即每次调用的时候传入唯一键，通过唯一键判断业务是否被操纵过，如果被操作则不再进行重复操作。   
     2，通过状态机处理，给业务设置状态，通过状态判断是否重复执行。   
     * 本地消息表   
     本地消息表是利用了各系统本地的事务来实现分布式事务。   
     本地消息表会有一张存放本地消息的表，一般是放在数据库中，然后再执行任务的时候**将业务的执行和消息放入本地消息表中的操作放在同一个事务中**，这样就能保证消息放入本地表中业务肯定是执行成功的。   
     然后再去调用下一个操作，如果下一个操作调用成功了好说，消息表的消息状态可以直接改成已成功。   
     如果调用失败也没事，会有 后台任务定时去读取本地消息表，筛选出还未成功的消息再调用对应的服务，服务更新成功了再变更消息的状态。   
     这时候有可能消息对应的操作不成功，因此也需要重试，重试就得保证对应服务的方法是幂等的，而且一般重试会有最大次数，超过最大次数可以记录下报警让人工处理。   
     可以看到本地消息表其实实现的是最终一致性，容忍了数据暂时不一致的情况。   
     * MQ事务   
     在RocketMQ中实现了分布式事务，实际上其实是对本地消息表的一个封装，将本地消息表移动到了MQ内部。   
      ![avatar](https://github.com/NPFDamon/Study/blob/main/src/main/resources/distributed/mq-trans-1.png)     
      第一阶段，准备消息，会拿到消息的地址。   
      第二阶段，执行本地事务。   
      第三阶段，会根据第一阶段拿到的地址去访问消息，并修改状态。消息接受者就能使用这个消息。   
      如果消息失败，在RocketMq Broker中提供了定时扫描没有更新状态的消息，如果消息没有的到确认，回想向消息的发送者发送消息来判断是否提交，在rocketmq中是以listener的形式给发送者，用来处理。   
      ![avatar](https://github.com/NPFDamon/Study/blob/main/src/main/resources/distributed/mq-trans-2.png)     
      如果消费超时，则需要一直重试，消息接收端需要保证幂等。如果消息消费失败，这个就需要人工进行处理，因为这个概率较低，如果为了这种小概率时间而设计这个复杂的流程反而得不偿失。    
      * Saga事务   
      其核心思想是将长事务拆分为多个本地短事务，由Saga事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。
      Saga的组成：
      每个Saga由一系列sub-transaction Ti 组成。   
      每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果,这里的每个T，都是一个本地事务。   
      可以看到，和TCC相比，Saga没有“预留 try”动作，它的Ti就是直接提交到库。   
+ [**Seata**](http://seata.io/zh-cn/docs/overview/what-is-seata.html)    
      Seata 也是从两段提交演变而来的一种分布式事务解决方案，提供了 AT、TCC、SAGA 和 XA 等事务模式。   
      Seata的几种角色：   
      - Transaction Coordinator(TC)： 全局事务协调者，用来协调全局事务和各个分支事务(不同服务)的状态，驱动全局事务和各个分支事务的回滚或提交。   
      - Transaction Manager(TM): 事务管理者，业务层中用来开启/回滚/提交一个整体事务(在调用服务的方法中用注解开启事务)。   
      - Resource Manager(RM)： 资源管理者，一般业务数据库代表一个分支事务(Branch Transaction)，管理分支事务与TC进行协调注册分支事务，并汇报分支
      事务的状态，驱动分支事务的提交会回滚。   
      `Seata 实现分布式事务，设计了一个关键角色 UNDO_LOG （回滚日志记录表），我们在每个应用分布式事务的业务库中创建这张表，这个表的核心作用就是，
      将业务数据在更新前后的数据镜像组织成回滚日志，备份在 UNDO_LOG 表中，以便业务异常能随时回滚。`
     
            
    
    
    